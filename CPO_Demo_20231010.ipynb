{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e64ffc91-0f0c-4ecf-9431-2e88553f3207",
   "metadata": {},
   "source": [
    "### Demo Notebook For CPO 2.0 API\n",
    "This notebook presents how to connect to the CPO 2.0 API, manage files, set up parameters and request predictions. It also covers the requirement on and format of input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36ed55fd-5ec7-42ed-827b-f24bdf0fa01d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'message': 'Welcome to CPO API 2.0.6'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import statement\n",
    "import os\n",
    "import datetime\n",
    "import time\n",
    "import requests\n",
    "import json\n",
    "\n",
    "# user info, user_email is the main identifier and will be used to send result and notification\n",
    "# please change the user_email to your email address, since all notification will be sent to the email\n",
    "user = \"Demo User\"\n",
    "user_email = \"me@office.com\"\n",
    "\n",
    "# connect to the VM, a welcome message will display if connected\n",
    "api_host = 'http://localhost:5005/'      # for debug purposes\n",
    "resp = requests.get(api_host, verify=False)\n",
    "resp_json = resp.content\n",
    "json.loads(resp_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7825e1d6-f5f4-4f3c-bc9d-543feaab7b14",
   "metadata": {},
   "source": [
    "### Uploading Data\n",
    "CPO requires daily returns data and constraints on each portfolio components as inputs. User can also upload additional features. These data are stored in separate directories under the client's account. If a new data file is re-uploaded under the same file name, the existing file will be overwritten. This can be used to update the return file for live predictions.\n",
    "\n",
    "#### Return File\n",
    "Return file should contain daily return of all or a superset of the components in the portfolio universe, with `return(t) = close(t) / close(t-1) - 1.0`. The return file should have a `Date` (alias `tradedate`, `time`, `timestamp`, `datetime`) column for indexing purposes, and the desired format is `yyyy-mm-dd`. Upon uploading the return file, CPO API will identify the `Date` column and provides feedbacks on the start- and end-dates so user can check if the processing is successful. User can upload multiple return files but only one return file can be used for each portfolio.\n",
    "\n",
    "CPO API will take all other columns as daily returns of portfolio components. NaNs and zeros and treated differently for these return columns. To be specific, NaNs are for historical period when the ticker *does not exist*, while zeros are taken as *real zero returns* (e.g. due to holidays). *Please contact PredictNow if your return data is sparse.*\n",
    "\n",
    "The following code upload the `ETF_return.csv` file from the `Data` directory, then list all available return files under the account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99bb738b-80c1-48f2-972a-a0d7f2446e43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading return files\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'message': 'Date info from date with 16 return columns. Index range between 2010-01-04 and 2023-03-03.'}\n",
      "====================================================================================================\n",
      "{'Uploaded return_data files': ['ETF_return.csv', 'ETF_return2.csv', 'ETF_return99.csv']}\n"
     ]
    }
   ],
   "source": [
    "# upload return file, validation result will be displayed\n",
    "print(\"Uploading return files\")\n",
    "return_filename = \"ETF_return.csv\"\n",
    "upload_file = open(file=os.path.join(\".\", \"Data\", return_filename), mode=\"rb\")\n",
    "data = {\n",
    "    \"type\": \"Returns\", \n",
    "    \"email\": user_email,\n",
    "}\n",
    "resp = requests.post(f\"{api_host}upload-data\", files={\"file\": upload_file}, data=data, verify=False)\n",
    "print(json.loads(resp.content))\n",
    "\n",
    "# also list what return files have been uploaded\n",
    "resp = requests.get(f\"{api_host}list-return-files/{user_email}\", verify=False)\n",
    "resp_json = resp.content\n",
    "resp_content = json.loads(resp_json)\n",
    "print(\"=\" * 100)\n",
    "print(resp_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ec3143-5d3c-4605-a712-6c7acf6d7c30",
   "metadata": {},
   "source": [
    "#### Constrain files\n",
    "The constraint file defines the portfolio universe and the upper and lower boundaries (min and max allocation) of each components. There should be a `component` column for the component names, and these names should also be a subset of the return columns of the return file to be used. The column names are case sensitive. The upper and lower boundaries of each component should be given in the `UB` and `LB` columns, and their default values are 0.0 (0%) and 1.0 (100%) if not provided for a given component. Each user can upload multiple constraint files under different names, but only one constraint file can be used for each portfoio.\n",
    "\n",
    "The following code upload the `ETF_constrain.csv` file from the `Data` directory, then list all available constraint files under the account. Note that `ETF_constrain.csv` contains fewer components than the `ETF_return.csv` file, in which case the additional ETFs will not be used to construct the portfolio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d62b2b57-3b93-46c3-9eca-7c6babf44b89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading constraint files\n",
      "{'message': 'Constraint file processed for 6 components'}\n",
      "====================================================================================================\n",
      "{'Uploaded constraint_data files': ['ETF_constrain.csv']}\n"
     ]
    }
   ],
   "source": [
    "# upload constraint file, validation result will be displayed\n",
    "print(\"Uploading constraint files\")\n",
    "constraint_filename = \"ETF_constrain.csv\"\n",
    "upload_file = open(file=os.path.join(\".\", \"Data\", constraint_filename), mode=\"rb\")\n",
    "data = {\n",
    "    \"type\": \"Constraint\", \n",
    "    \"email\": user_email,\n",
    "}\n",
    "resp = requests.post(f\"{api_host}upload-data\", files={\"file\": upload_file}, data=data, verify=False)\n",
    "print(json.loads(resp.content))\n",
    "\n",
    "# also list what constraints files are uploaded\n",
    "resp = requests.get(f\"{api_host}list-constraint-files/{user_email}\", verify=False)\n",
    "resp_json = resp.content\n",
    "resp_content = json.loads(resp_json)\n",
    "print(\"=\" * 100)\n",
    "print(resp_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd17a539-76c3-4b03-a4fd-3505b68c7fd6",
   "metadata": {},
   "source": [
    "#### Feature files (Optional)\n",
    "\n",
    "User can provide additional feature files to help prediction. Feature files are time-series files just like returns, so the key column is also `Date` (alias `tradedate`, `time`, `timestamp`, `datetime`). The desired format is `yyyy-mm-dd` for the ease of auto-processing. The clinet's features are merged with pre-engineered features at PredictNow by matching the `Date` column, and CPO API assumes all features are available before the open of market of the target date. All features are forward filled (using the latest one that is available) before training. User can upload multiple feature files.\n",
    "\n",
    "The following code upload the `Random_Feature.csv` file from the `Data` directory, then list all available client feauture files under the account. The uploaded feature are randomly generated and should not provide any prediction power."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40e99d6b-0266-4ba3-8414-92659e7fb895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading feature files\n",
      "{'message': 'Date info from TradeDate with 4 return columns. Index range between 2015-01-02 and 2022-08-02.'}\n",
      "====================================================================================================\n",
      "{'Uploaded feature_data files': ['Random_Feature.csv']}\n"
     ]
    }
   ],
   "source": [
    "# upload feature file, validation result will be displayed\n",
    "print(\"Uploading feature files\")\n",
    "feature_filename = \"Random_Feature.csv\"\n",
    "upload_file = open(file=os.path.join(\".\", \"Data\", feature_filename), mode=\"rb\")\n",
    "data = {\n",
    "    \"type\": \"features\", \n",
    "    \"email\": user_email,\n",
    "}\n",
    "resp = requests.post(f\"{api_host}upload-data\", files={\"file\": upload_file}, data=data, verify=False)\n",
    "print(json.loads(resp.content))\n",
    "\n",
    "# also list what constraints files are uploaded\n",
    "resp = requests.get(f\"{api_host}list-feature-files/{user_email}\", verify=False)\n",
    "resp_json = resp.content\n",
    "resp_content = json.loads(resp_json)\n",
    "print(\"=\" * 100)\n",
    "print(resp_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25bba93-41cb-4498-8956-521a73ff16f9",
   "metadata": {},
   "source": [
    "### Parameters\n",
    "\n",
    "There are certain parameters that are required to run a CPO job, and these parameters generally fall into two categoraries: a) those define the property of the target portfolio, like what components are included, how often it is rebalanced, what is the metric to rebalanced etc., and b) parameter that define the job, like what period of time should be used as in-sample, or what is the target date for a live prediction. \n",
    "\n",
    "This section focuses on the first part of the parameters, while the job-related parameters will be described in later sections. But before diving into the parameters, we will talke about the important idea of *project* in CPO API.\n",
    "\n",
    "#### Project\n",
    "\n",
    "CPO is designed to determine the allocation of a portfolio during each rebalancing, but not for ticker selection or tune the optimized rebalancing frequency. These configurations are like hyper-parameters of the portfolio, and users can use projects to test different portfolio configurations like:\n",
    "\n",
    "- What if I do weekly rebalancing instead of monthly rebalancing?\n",
    "- What if I lower the max allocation of some high-risk components and allow certain amount of Cash allocation?\n",
    "- What if I include additional features that I think might be helpful?\n",
    "etc.\n",
    "\n",
    "In short, each project corresponds to a specific portfolio set up that is defined by the portfolio parameters.\n",
    "\n",
    "#### Portfolio parameters\n",
    "The following parameters define the portfolio and should be fixed for a given project throughthout in-sample, out-of-sample, and live-prediction. \n",
    "\n",
    "- `email`, mandatory, user identification, e.g. `me@office.com`\n",
    "- `project_name`, mandatory, project / portfolio identification, e.g. `Demo_Project`\n",
    "- `return_file`, mandatory, daily return filename, should be uploaded first, e.g. `ETF_return.csv`\n",
    "- `constraint_file`, mandatory, portfolio components and their min and max allocations, should be uploaded first, e.g. `ETF_constraint.csv`. Note it's the `component` column in the `constraint_file` that defines the current portfolio universe.\n",
    "- `feature_file`, optional, 'none' or 'feature_file1.csv, feature_file2.csv, ...', clinet feature to be included, and these files should be uploaded first.\n",
    "- `skip_PNow_feature`, optional, if set to 'yes', 'true', or 'skip', will not include predictnow features. Note, if `feature_file` is not provided (`none` or not in the parameter dictionary) there would be no X-columns in the prediction model.\n",
    "- `max_cash`, mandatory, maximum cash allocation allowed when risk is predicted to be large, float between 0 and 1 where 1 correspond to 100% (no market exposure).\n",
    "- `rebalancing_period_unit`, mandatory, 'week' or 'month', used with `rebalancing_period`.\n",
    "- `rebalancing_period`, mandatory, int. If `rebalancing_period = 2` and `rebalancing_period_unit = 'week'`, the portfolio would rebalanced every other week.\n",
    "- `rebalance_on`, mandatory, 'first' or 'last', determine if the portfolio is rebalanced at the close of the first or last market day of the rebalancing period. Please see next subsection on how the dates are indexed in CPO.\n",
    "- `training_data_size`, mandatory, int, in the unit of years, size of rolling window that is used to make the prediction for each rebalancing.\n",
    "- `evaluation_metric`, mandatory, key performance metric to optimize, can be chosen from 'return', 'risk', 'sharpe', 'CAGR', 'UI', 'UPI', or 'MaxDD'. For risk related metrics, i.e. 'risk', 'UI', and 'MaxDD', `max_cash` will be overridden since Cash will always have zero and hence the minimal risk.\n",
    "\n",
    "The code below gives how to set up the portfolio parameters, with some optional ones commented out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cbad9120-09dd-473e-b91b-f60c203322a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "portfolio_params = {\n",
    "    \"email\": user_email,\n",
    "    \"project_name\": \"Demo_Project_20231211\",\n",
    "    \"returns_file\": \"ETF_return.csv\",\n",
    "    \"constraint_file\": \"ETF_constrain.csv\",\n",
    "    # \"feature_file\": \"Random_Feature.csv\",\n",
    "    # \"skip_PNow_feature\": \"skip\",\n",
    "    \"max_cash\": 1.0,\n",
    "    \"rebalancing_period_unit\": \"month\",\n",
    "    \"rebalancing_period\": 1,\n",
    "    \"rebalance_on\": \"first\",\n",
    "    \"training_data_size\": 3,\n",
    "    \"evaluation_metric\": \"sharpe\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6a2ea2-cef5-428e-bea2-6517fd44c929",
   "metadata": {},
   "source": [
    "#### Additional Notes on how CPO Handles Date index\n",
    "There are two sets of date that are tightly related to each other, the rebalance period, and the rebalancing date.\n",
    "\n",
    "Rebalance period is usually labelled by the first calendar day within the period, regardless of if it is a valid market day. The start date of the first rebalancing period is taken from the `training_start_date` when in-sample or out-of-sample backtesting is requested. After that, the enxt start date would be the previous start date plus the date offset of the rebalancing period (e.g. 1 months, 2 weeks etc.). These dates are for indexing purposes, especially for CPO API to store and manage data files for each rebalancing period. The back-testing experiment will stop when the start date of the rebalancing period is larger than the `training_end_date`. \n",
    "\n",
    "The start date of a rebalancing period can be any calendar day and may not be an effective rebalancing (market) day. To determine the actual rebalancing date of the rebalancing period, CPO requires the knowledge on when the rebalancing should take place, i.e. the `rebalane_on` parameter. If `rebalance_on` is set to 'first', then CPO will use the first marketday within the rebalancing period; otherwise if `rebalance_on` is set to 'last', then the rebalancing date will be taken from the last market day of the PREVIOUS rebalancing period."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5540f4-5bc1-432f-b052-afd71629a0d6",
   "metadata": {},
   "source": [
    "### Backtesting\n",
    "\n",
    "Backtesting can be further divided into in-sample and out-of-sample backtestings. CPO uses the in-sample period to tune hyper-parameters of the prediction system, including selection of candidate strategies, type of prediction model to be used, and aggregation function that turns predictions into final recommendations. The tuned hyper-parameters will be saved, and user can use out-of-sample period to verify if CPO continuous to add values. Both in-sample and out-of-sample backtesting jobs require some additional parameters then those defined the portfolio.\n",
    "\n",
    "#### In-sample backtesting\n",
    "\n",
    "In-sample backtesting is used to determine the hyper-parameters of the CPO system. The parameters required for in-sample backtesting include:\n",
    "- `training_start_date`, mandatory, in the format of 'yyyy-mm-dd', the start date of the first rebalancing period to be included in the experiment. \n",
    "- `training_end_date`, mandatory, in the format of 'yyyy-mm-dd', the experiment terminates when the start of the period exceed the `training_end_date`.\n",
    "- `sampling_rate`, mandatory, float between 0 and 1, the fraction of base strategies to be kept. This parameter is usually set to 0.3 or 0.4.\n",
    "- `debug`, optional, will output more information in the backend when set to `debug`, and will not affect the performance or prediction.\n",
    "\n",
    "The following code submit an in-sample backtesing job between Jan and Dec 2023 for the demo portfolio defined earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "985be02e-60d1-4b18-a0f3-89aa6f8fa33a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'message': 'job submitted for cpo in-sample backtesting.', 'task_id': '8b728606-1451-4bbb-b338-c691a0c32ccd'}\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    \"training_start_date\": \"2019-01-01\",\n",
    "    \"training_end_date\": \"2019-12-31\",\n",
    "    \"sampling_proportion\": 0.3,\n",
    "    \"debug\": \"debug\",\n",
    "}\n",
    "params.update(portfolio_params)\n",
    "\n",
    "uri = f\"{api_host}run-insample-backtest\" \n",
    "resp = requests.post(uri, json=params, verify=False)\n",
    "resp_content = json.loads(resp.content)\n",
    "cpo_job_id_backtest = resp_content['task_id']\n",
    "print(resp_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b816e5-bc67-412a-a17a-ce46e13223e0",
   "metadata": {},
   "source": [
    "#### Time cost of in-sample backtesting\n",
    "It can take 20 - 30 min for each rebalancing period within the in-sample period, depending on no. of components in the portfolio, size of training data, and the sampling proportion. The time cost can add up quickly when the test includes many rebalancing period, eithor due to more frequently rebalancing (e.g. weekly) or longer testing period. User can use the `get-cpo-job-status` function to check current status. CPO API will return the performance metrics of the tuned model after the job is finished, and the corresponding allocations will be sent to user's email. These weights can be loaded using a separate function as well, see later section.\n",
    "\n",
    "It is also possible that, due to the long-running nature of the back-testing jobs (both in-sample and out-of-sample), there could be connection errors that create a breaking point. In that case, **simply re-submit the training request without chaning any parameters.** There is breaking-point handling modules in CPO API that record the progress and will continue the job from the most recent breaking point. This is true for both in-sample and out-of-sample backtesting.\n",
    "\n",
    "The following code check the progress of the back-testing submited, and output the performance if job is finished."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "471dc8e2-3753-4d94-8688-427cc6b15694",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cpo_job_id': '8b728606-1451-4bbb-b338-c691a0c32ccd', 'cpo_job_status': 'SUCCESS', 'cpo_result': \"{'return': 0.17429690353749647, 'risk': 0.0241256100193871, 'sharpe': 7.224559436939966, 'CAGR': 0.189991246453467, 'UI': 0.09178534874175193, 'UPI': 189.89621538389505, 'MaxDD': 0.0032538487588696543}\", 'progress': '{\"step\": 5, \"progress\": \"In sample backtesting copleted, preparing outputs\"}'}\n",
      "2023-12-11 23:07:51.022386\n",
      "Current Status: SUCCESS\n",
      "==================================================\n",
      "CPO RESULTS\n",
      "{'return': 0.17429690353749647, 'risk': 0.0241256100193871, 'sharpe': 7.224559436939966, 'CAGR': 0.189991246453467, 'UI': 0.09178534874175193, 'UPI': 189.89621538389505, 'MaxDD': 0.0032538487588696543}\n"
     ]
    }
   ],
   "source": [
    "# check status of the in-sample backtesting job progress and output performance if finished.\n",
    "resp = requests.get(f\"{api_host}get-cpo-job-status/{cpo_job_id_backtest}\", verify=False)\n",
    "resp_json = resp.content\n",
    "resp_content = json.loads(resp_json)\n",
    "print(resp_content)\n",
    "\n",
    "#print(\"Response:\", resp_content)\n",
    "status = resp_content['cpo_job_status']\n",
    "print(datetime.datetime.now())\n",
    "print(\"Current Status:\", status)\n",
    "if status=='SUCCESS': \n",
    "    print(\"=\"*50)\n",
    "    print(\"CPO RESULTS\")\n",
    "    result = resp_content['cpo_result']\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68fb890f-b869-4f8d-a421-36711f9f8fb8",
   "metadata": {},
   "source": [
    "#### Out of Sample Backteting\n",
    "\n",
    "Out of sample backtesting simply applies the hyper-parameters tuned during in-sample periods and test if they continue to add value over a different time period. That means, out-of-sample test can only be run after in-sample tuning is finished. The required input parameters are `training_start_date` and `training_end_date`, with the same definition and format as in-sample backtesting.\n",
    "\n",
    "It is important to keep the `training_start_date` parameters have the same format for in-sample and out-of-sample tests. For this example we are working on a portfolio that takes monthly rebalance on the first market day of the month, so we will keep `training_start_date` to the 1st of the month in OOS. Similarly, if in-sample test starts on a Monday for a weekly rebalanced portfolio, the OOS should start on the next Monday as well. \n",
    "\n",
    "OOS test generally runs faster than in-sample because there are fewer models to be run, but may still take 15 min for each rebalancing period.\n",
    "\n",
    "The following code submits an out-of-sample job for the demo portfolio between Jan and Jun 2022. The prediction will be made using configurations determined during in-sample testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ddfa61d1-56f7-474b-9f0b-5b1aea8ee773",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'message': 'job submitted for cpo back-testing.', 'task_id': '3b32a5c7-c098-450a-8014-fe48ae5425cb'}\n"
     ]
    }
   ],
   "source": [
    "# oos prediction\n",
    "params = {\n",
    "    \"training_start_date\": \"2020-01-01\",\n",
    "    \"training_end_date\": \"2020-12-31\",\n",
    "    \"debug\": \"debug\",\n",
    "}\n",
    "params.update(portfolio_params)\n",
    "\n",
    "uri = f\"{api_host}run-oos-backtest\" \n",
    "resp = requests.post(uri, json=params, verify=False)\n",
    "resp_content = json.loads(resp.content)\n",
    "cpo_job_id_backtest = resp_content['task_id']\n",
    "print(resp_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "27bd01a7-c468-40b9-87aa-8196b6410115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cpo_job_id': '3b32a5c7-c098-450a-8014-fe48ae5425cb', 'cpo_job_status': 'PENDING', 'cpo_result': 'None', 'progress': '{\"step\": 1, \"progress\": \"Training models\"}'}\n",
      "2023-11-26 22:05:36.031587\n",
      "Current Status: PENDING\n"
     ]
    }
   ],
   "source": [
    "# check status\n",
    "resp = requests.get(f\"{api_host}get-cpo-job-status/{cpo_job_id_backtest}\", verify=False)\n",
    "resp_json = resp.content\n",
    "resp_content = json.loads(resp_json)\n",
    "print(resp_content)\n",
    "\n",
    "#print(\"Response:\", resp_content)\n",
    "status = resp_content['cpo_job_status']\n",
    "print(datetime.datetime.now())\n",
    "print(\"Current Status:\", status)\n",
    "\n",
    "if status=='SUCCESS': \n",
    "    print(\"=\"*50)\n",
    "    print(\"CPO RESULTS\")\n",
    "    result = resp_content['cpo_result']\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6579846-b399-4efb-9c3a-1fd29718e31a",
   "metadata": {},
   "source": [
    "#### Load Backtesting Results\n",
    "\n",
    "The predictions generated during in-sample and out-of-sample backtesting experiments are stored on CPO API. Users can request these results for in-sample, out-of-sample, or combined. The key parameters are, again, `training_start_date` and `training_end_date`.\n",
    "\n",
    "The following requests the CPO allocations and its performance for the entire back-testing period (in-sample + out-of-sample)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fbf1a23a-64ee-4ef1-80c9-ab3e7fa73ab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Loading backtesting weights\n",
      "{'2019-01-02': {'SPY': 0.0539468147, 'QQQ': 0.0346698355, 'VNQ': 0.0331834347, 'REM': 0.1002935535, 'IEF': 0.2798133149, 'TLT': 0.1904534153}, '2019-02-01': {'SPY': 0.0446511781, 'QQQ': 0.039910024, 'VNQ': 0.0463260017, 'REM': 0.0524557947, 'IEF': 0.1055622018, 'TLT': 0.0640442022}, '2019-03-01': {'SPY': 0.07094082, 'QQQ': 0.0683798591, 'VNQ': 0.0799032846, 'REM': 0.1146294247, 'IEF': 0.2425103942, 'TLT': 0.110000258}}\n",
      "                 SPY      QQQ       VNQ       REM       IEF       TLT\n",
      "2019-01-02  0.053947  0.03467  0.033183  0.100294  0.279813  0.190453\n",
      "2019-02-01  0.044651  0.03991  0.046326  0.052456  0.105562  0.064044\n",
      "2019-03-01  0.070941  0.06838  0.079903  0.114629  0.242510  0.110000\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'a' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-4e0346a536be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp_content\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"=\"\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'a' is not defined"
     ]
    }
   ],
   "source": [
    "# get backtesting weights\n",
    "params = {\n",
    "    \"training_start_date\": \"2019-01-01\",\n",
    "    \"training_end_date\": \"2020-03-31\",    # note dates can cover in-sample and OOS at the same time\n",
    "    \"debug\": \"debug\",\n",
    "}\n",
    "params.update(portfolio_params)\n",
    "\n",
    "print(\"=\"*50)\n",
    "print(\"Loading backtesting weights\")\n",
    "uri = f\"{api_host}get-backtest-weights\" \n",
    "resp = requests.get(uri, json=params, verify=False)\n",
    "resp_content = json.loads(resp.content)\n",
    "print(resp_content)\n",
    "\n",
    "# can also turn output into a pandas dataframe\n",
    "import pandas as pd\n",
    "df = pd.DataFrame.from_dict(resp_content).T\n",
    "print(\"=\"*50)\n",
    "print(\"Backtesting Weights as Dataframe\")\n",
    "print(df)\n",
    "\n",
    "print(\"=\"*50)\n",
    "print(\"Loading backtesting performance\")\n",
    "uri = f\"{api_host}get-backtest-performance\"     \n",
    "resp = requests.get(uri, json=params, verify=False)\n",
    "resp_content = json.loads(resp.content)\n",
    "print(resp_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e40a7b-1783-4588-a9a4-86b931a85002",
   "metadata": {},
   "source": [
    "### Live Prediction\n",
    "\n",
    "Live prediction means to use the tuned hyper-parameter to make prediction for an incoming rebalancing period. Live prediction requires the knowledge of a) the target rebalancing date, and b) the prediction horizon, i.e. how many market days are there in the incoming rebalancing period. User can provide the informaion using the following parameters:\n",
    "\n",
    "- `rebalance_date`, mandatory, in the format of 'yyyy-mm-dd', the target rebalance date.\n",
    "- `next_rebalance_date`, optional, in the format of 'yyyy-mm-dd', the next rebalance date after current target date. For example, for a weekly-rebalanced portfolio, if the `rebalance_date` is set to '2023-10-02', the `next_rebalance_date` would be Monday '2023-10-09'. If `next_rebalance_date` is passed, CPO will use US market calendar to determine how many market days are there in the target rebalancing period.\n",
    "- `n_days`, optional, int, the number of market days in the incoming rebalancing period. For a weekly rebalanced portfolio, `n_days` is usually 5 unless there is a holiday. This parameter overrides `next_rebalance_date`.\n",
    "\n",
    "If neithor `next_rebalance_date` nor `n_days` parameters are passed, CPO will infer the number of market days from rebalancing frequency by assuming 5 market days a week and 21 market days a month.\n",
    "\n",
    "The following code submit a live prediction training request, check the progress, then load the predicted allocation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5900b1-9563-457e-94b6-abfa19b5c337",
   "metadata": {},
   "outputs": [],
   "source": [
    "# live prediction\n",
    "params = {\n",
    "    \"rebalance_date\": \"2022-07-01\",\n",
    "    \"next_rebalance_date\": \"2022-08-01\",\n",
    "    \"debug\": \"debug\",\n",
    "}\n",
    "params.update(portfolio_params)\n",
    "\n",
    "uri = f\"{api_host}run-live-prediction\" \n",
    "resp = requests.post(uri, json=params, verify=False)\n",
    "resp_content = json.loads(resp.content)\n",
    "cpo_job_id_live = resp_content['task_id']\n",
    "print(resp_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f501469-8986-4493-837b-3388eacae120",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check status, and if training finished, load weights\n",
    "resp = requests.get(f\"{api_host}get-cpo-job-status/{cpo_job_id_live}\", verify=False)\n",
    "resp_json = resp.content\n",
    "resp_content = json.loads(resp_json)\n",
    "print(resp_content)\n",
    "\n",
    "status = resp_content['cpo_job_status']\n",
    "print(datetime.datetime.now())\n",
    "print(\"Current Status:\", status)\n",
    "\n",
    "# print out weights\n",
    "if status=='SUCCESS': \n",
    "    result = resp_content['cpo_result']\n",
    "    print(\"CPO RESULTS\")\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0b5493-4e0d-402c-8b41-296ba8939d81",
   "metadata": {},
   "source": [
    "After the job prediction is made, user can also load the result without redo the training with the following code. The key parameter is `rebalance_date`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53fd6f9a-757e-4012-8118-71e8a7a7bb32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# can also load live prediction weights after the training is finished\n",
    "params = {\n",
    "    \"rebalance_date\": \"2022-07-01\",\n",
    "    \"debug\": \"debug\",\n",
    "}\n",
    "params.update(portfolio_params)\n",
    "uri = f\"{api_host}get-live-prediction-weights\" \n",
    "resp = requests.get(uri, json=params, verify=False)\n",
    "resp_content = json.loads(resp.content)\n",
    "print(resp_content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
