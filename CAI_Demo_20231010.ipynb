{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CAI demo notebook\n",
    "For demo purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic import statements\n",
    "from predictnow.pdapi import PredictNowClient\n",
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic configuration\n",
    "# User ID\n",
    "username = \"variable29\"    # \"variable29\", only letters, numbers, or underscores\n",
    "email = \"variable29@gmail.com\"    # \"variable29@gmail.com\"\n",
    "\n",
    "# connect to API\n",
    "makeshiftapi_host = \"http://127.0.0.1:5000/\"      # local host for debugging purposes only\n",
    "\n",
    "api_key = \"--------\"\n",
    "client = PredictNowClient(makeshiftapi_host,api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           date       SPY\n",
      "2013 2018-01-02  0.007157\n",
      "2014 2018-01-03  0.006325\n",
      "2015 2018-01-04  0.004215\n",
      "2016 2018-01-05  0.006664\n",
      "2017 2018-01-08  0.001829\n",
      "...         ...       ...\n",
      "3309 2023-02-27  0.003406\n",
      "3310 2023-02-28 -0.003696\n",
      "3311 2023-03-01 -0.003836\n",
      "3312 2023-03-02  0.007777\n",
      "3313 2023-03-03  0.016038\n",
      "\n",
      "[1301 rows x 2 columns]\n",
      "42\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "# load and process data\n",
    "input_filename = \"ETF_return.csv\"   # pre-processed to shift the date by one role\n",
    "df_return = pd.read_csv(os.path.join(\".\", \"Data\", input_filename), parse_dates=[\"date\"])\n",
    "\n",
    "# CAI predicts the sign of a single return stream, and any additional columns will be taken as features\n",
    "# so we will only keep SPY in this demo\n",
    "target_label = \"SPY\"\n",
    "df_return = df_return[[\"date\", target_label]].iloc[1:].copy()\n",
    "\n",
    "# train test split. Here we will use all data between 2018 and 2023 as training data set to predict returns of 2023\n",
    "# you can change the training time window and testing period accordingly\n",
    "# they are actually sent together as on file to the API, but we do need to determine their sizes.\n",
    "df_train = df_return.loc[(df_return[\"date\"] >= pd.to_datetime(\"2018-01-01\")) & (df_return[\"date\"] <= pd.to_datetime(\"2022-12-31\"))]\n",
    "df_test = df_return.loc[df_return[\"date\"] >= pd.to_datetime(\"2023-01-01\")]\n",
    "df_input = pd.concat([df_train, df_test])\n",
    "\n",
    "# finally a quick snap on the data\n",
    "print(df_input)\n",
    "print(str(len(df_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model configuration\n",
    "model_name = \"DemoModel\"\n",
    "params= {\n",
    "    \"timeseries\": \"no\",          # (yes, no)\n",
    "    \"type\": \"classification\",    # (classification, regression)\n",
    "    \"feature_selection\": \"shap\", # (shap, cmda, none)\n",
    "    \"analysis\": \"small\",         # (small, none)\n",
    "    \"boost\": \"gbdt\",             # (dart, gbdt)\n",
    "    \"mode\": \"train\",             # (train, live)\n",
    "    \"testsize\": str(len(df_test)),   # testsize < 1 --> ratio, > 1 --> exact # of rows, we are using the size of df_test here\n",
    "    \"weights\": \"no\",             # (yes, no, custom)\n",
    "    \"prob_calib\": \"no\",          # (yes, no) -> refine your probability\n",
    "    \"eda\": \"no\",                # (yes, no) -> exploratory data analysis\n",
    "    \"random_seed\":\"1\",    # random seed for initialization, default=1\n",
    "    \"custom_weights\":\"\",\n",
    "    \"pre_engg_features_list\": [\"all\"]  #['TR', 'CANARY', 'NOPE', 'OF'], Comment this param out in case it is not required to be used.\n",
    "    #cmda added features\n",
    "    # \"cmda_corr_method\":\"PEARSON\", # pearson,kendall,spearman\n",
    "    # \"cmda_n_clusters\":\"3\",\n",
    "    # \"cmda_select_top_n_clusters\":\"4\",\n",
    "    #\"mandatory_features\":['sma_5'],\n",
    "}\n",
    "df_input.name = model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response - create_model\n",
      "{'message': 'Successfully stored the model', 'success': True, 'model_name': 'DemoModel'}\n"
     ]
    }
   ],
   "source": [
    "# create model and send training request\n",
    "response = client.create_model(\n",
    "    username=username, \n",
    "    model_name=model_name,\n",
    "    params=params,\n",
    ")\n",
    "print(\"Response - create_model\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "in false\n",
      "return_op True\n",
      "Response - train\n",
      "{'message': 'Training the model is successfully requested.', 'model_name': 'saved_model_DemoModel.pkl', 'success': True, 'train_id': '982d529c-d654-4cfc-a8de-e52e0fb16df0'}\n"
     ]
    }
   ],
   "source": [
    "# start training, there will be an error message!\n",
    "response = client.train(\n",
    "    model_name=model_name,\n",
    "    input_df=df_input,\n",
    "    label=target_label,\n",
    "    username=username,\n",
    "    email=email,\n",
    "    #external_feature=True\n",
    ")\n",
    "print('Response - train')\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current status:\n",
      "{'status': 'Prediction completed! Experiment complete.', 'current': 6, 'datetime': '2023-12-19 16:45:07.795215', 'state': 'COMPLETED', 'result': 'Experiment complete', 'total': 6}\n"
     ]
    }
   ],
   "source": [
    "# check status\n",
    "status = client.getstatus(\n",
    "    username=username,\n",
    "    train_id=response[\"train_id\"]\n",
    ")\n",
    "print(\"Current status:\")\n",
    "print(status)\n",
    "# cannot move on unter experiment is finished"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_prob_cv\n",
      "      Unnamed: 0       date       0.0       1.0\n",
      "0              0 2018-01-02  0.006849  0.993151\n",
      "1              1 2018-01-03  0.220018  0.779982\n",
      "2              2 2018-01-04  0.156282  0.843718\n",
      "3              3 2018-01-05  0.090680  0.909320\n",
      "4              4 2018-01-08  0.430789  0.569211\n",
      "...          ...        ...       ...       ...\n",
      "1254        1254 2022-12-23  0.440742  0.559258\n",
      "1255        1255 2022-12-27  0.029810  0.970190\n",
      "1256        1256 2022-12-28  0.572378  0.427622\n",
      "1257        1257 2022-12-29  0.077087  0.922913\n",
      "1258        1258 2022-12-30  0.958594  0.041406\n",
      "\n",
      "[1259 rows x 4 columns]\n",
      "predicted_prob_test\n",
      "         date       0.0       1.0\n",
      "0  2023-01-03  0.907594  0.092406\n",
      "1  2023-01-04  0.913679  0.086321\n",
      "2  2023-01-05  0.357275  0.642725\n",
      "3  2023-01-06  0.949131  0.050869\n",
      "4  2023-01-09  0.708843  0.291157\n",
      "5  2023-01-10  0.927519  0.072481\n",
      "6  2023-01-11  0.583928  0.416072\n",
      "7  2023-01-12  0.946364  0.053636\n",
      "8  2023-01-13  0.335753  0.664247\n",
      "9  2023-01-17  0.708922  0.291078\n",
      "10 2023-01-18  0.841643  0.158357\n",
      "11 2023-01-19  0.802962  0.197038\n",
      "12 2023-01-20  0.102086  0.897914\n",
      "13 2023-01-23  0.955160  0.044840\n",
      "14 2023-01-24  0.262326  0.737674\n",
      "15 2023-01-25  0.564705  0.435295\n",
      "16 2023-01-26  0.184954  0.815046\n",
      "17 2023-01-27  0.659500  0.340500\n",
      "18 2023-01-30  0.042429  0.957571\n",
      "19 2023-01-31  0.974373  0.025627\n",
      "20 2023-02-01  0.969620  0.030380\n",
      "21 2023-02-02  0.168541  0.831459\n",
      "22 2023-02-03  0.718518  0.281482\n",
      "23 2023-02-06  0.035984  0.964016\n",
      "24 2023-02-07  0.810985  0.189015\n",
      "25 2023-02-08  0.890561  0.109439\n",
      "26 2023-02-09  0.743028  0.256972\n",
      "27 2023-02-10  0.893943  0.106057\n",
      "28 2023-02-13  0.979053  0.020947\n",
      "29 2023-02-14  0.718608  0.281392\n",
      "30 2023-02-15  0.402740  0.597260\n",
      "31 2023-02-16  0.953071  0.046929\n",
      "32 2023-02-17  0.665290  0.334710\n",
      "33 2023-02-21  0.767746  0.232254\n",
      "34 2023-02-22  0.729408  0.270592\n",
      "35 2023-02-23  0.314779  0.685221\n",
      "36 2023-02-24  0.969402  0.030598\n",
      "37 2023-02-27  0.609278  0.390722\n",
      "38 2023-02-28  0.481490  0.518510\n",
      "39 2023-03-01  0.560528  0.439472\n",
      "40 2023-03-02  0.407046  0.592954\n",
      "41 2023-03-03  0.650097  0.349903\n",
      "predicted_targets_cv\n",
      "      Unnamed: 0  true_target  pred_target\n",
      "0              0            1            1\n",
      "1              1            1            1\n",
      "2              2            1            1\n",
      "3              3            1            1\n",
      "4              4            1            1\n",
      "...          ...          ...          ...\n",
      "1254        1254            1            1\n",
      "1255        1255            0            1\n",
      "1256        1256            0            0\n",
      "1257        1257            1            1\n",
      "1258        1258            0            0\n",
      "\n",
      "[1259 rows x 3 columns]\n",
      "predicted_targets_test\n",
      "         date  true_target  pred_target\n",
      "0  2023-01-03            0            0\n",
      "1  2023-01-04            1            0\n",
      "2  2023-01-05            0            1\n",
      "3  2023-01-06            1            0\n",
      "4  2023-01-09            0            0\n",
      "5  2023-01-10            1            0\n",
      "6  2023-01-11            1            0\n",
      "7  2023-01-12            1            0\n",
      "8  2023-01-13            1            1\n",
      "9  2023-01-17            0            0\n",
      "10 2023-01-18            0            0\n",
      "11 2023-01-19            0            0\n",
      "12 2023-01-20            1            1\n",
      "13 2023-01-23            1            0\n",
      "14 2023-01-24            0            1\n",
      "15 2023-01-25            1            0\n",
      "16 2023-01-26            1            1\n",
      "17 2023-01-27            1            0\n",
      "18 2023-01-30            0            1\n",
      "19 2023-01-31            1            0\n",
      "20 2023-02-01            1            0\n",
      "21 2023-02-02            1            1\n",
      "22 2023-02-03            0            0\n",
      "23 2023-02-06            0            1\n",
      "24 2023-02-07            1            0\n",
      "25 2023-02-08            0            0\n",
      "26 2023-02-09            0            0\n",
      "27 2023-02-10            1            0\n",
      "28 2023-02-13            1            0\n",
      "29 2023-02-14            0            0\n",
      "30 2023-02-15            1            1\n",
      "31 2023-02-16            0            0\n",
      "32 2023-02-17            0            0\n",
      "33 2023-02-21            0            0\n",
      "34 2023-02-22            0            0\n",
      "35 2023-02-23            1            1\n",
      "36 2023-02-24            0            0\n",
      "37 2023-02-27            1            0\n",
      "38 2023-02-28            0            1\n",
      "39 2023-03-01            0            0\n",
      "40 2023-03-02            1            1\n",
      "41 2023-03-03            1            0\n",
      "feature_importance\n",
      "    Unnamed: 0         0\n",
      "0       NOPE_1  0.028866\n",
      "1        CAN_1  0.024660\n",
      "2        CAN_2  0.021757\n",
      "3      FSTS_37  0.021105\n",
      "4      FSTS_39  0.020998\n",
      "..         ...       ...\n",
      "188        F21  0.002521\n",
      "189        F27  0.002514\n",
      "190        F13  0.002392\n",
      "191        F29  0.002374\n",
      "192      CAN_3  0.002338\n",
      "\n",
      "[193 rows x 2 columns]\n",
      "performance_metrics\n",
      "  The range of the CV set is: 02-01-2018 00:00:00 to 30-12-2022 00:00:00\n",
      "0     THE ACCURACY SCORE FOR CV = 0.5782366957903098                    \n",
      "1           THE F1 SCORE FOR CV = 0.5751686949988205                    \n",
      "2           THE AUC SCORE FOR CV= 0.5800305110602594                    \n",
      "3  The range of the test set is: 03-01-2023 00:00...                    \n",
      "4   THE ACCURACY SCORE FOR TEST = 0.5238095238095238                    \n",
      "5         THE F1 SCORE FOR TEST = 0.5014005602240896                    \n",
      "6        THE AUC SCORE FOR TEST= 0.47045454545454546                    \n"
     ]
    }
   ],
   "source": [
    "# check training is finished\n",
    "assert status['state'] == \"COMPLETED\", \"Please wait for the training to finish.\"\n",
    "\n",
    "# load predictions\n",
    "response = client.getresult(\n",
    "        model_name=model_name,\n",
    "        username=username,\n",
    "    )\n",
    "# the response contains several groups of results, as follow:\n",
    "\n",
    "# predicted probability (float between 0 and 1) for validation/training data set, i.e. 2018 - 2022 in the demo experiment\n",
    "# the last column notes the probability that it's a \"1\", i.e. positive return\n",
    "predicted_prob_cv = pd.read_json(response.predicted_prob_cv)\n",
    "print(\"predicted_prob_cv\")\n",
    "print(predicted_prob_cv)\n",
    "\n",
    "# predicted probability (float between 0 and 1) for the testing data set, i.e. every row after 2023 in the demo experiment\n",
    "predicted_prob_test = pd.read_json(response.predicted_prob_test)\n",
    "print(\"predicted_prob_test\")\n",
    "print(predicted_prob_test)\n",
    "\n",
    "# predicted label, 0 or 1, for validation/training data set. Classified as class 1 if probability > 0.5\n",
    "predicted_targets_cv = pd.read_json(response.predicted_targets_cv)\n",
    "print(\"predicted_targets_cv\")\n",
    "print(predicted_targets_cv)\n",
    "\n",
    "# predicted label, 0 or 1, for testing data set. Classified as class 1 if probability > 0.5\n",
    "predicted_targets_test = pd.read_json(response.predicted_targets_test)\n",
    "print(\"predicted_targets_test\")\n",
    "print(predicted_targets_test)\n",
    "\n",
    "# feature importance score, shows what features are being used in the prediction\n",
    "# more helpful when you include your features\n",
    "# and only works when you set param['feature_selection'] to shap or cmda\n",
    "if response.feature_importance:\n",
    "    feature_importance = pd.read_json(response.feature_importance)\n",
    "    print(\"feature_importance\")\n",
    "    print(feature_importance)\n",
    "\n",
    "# performance metrics in terms of accuracies and so on\n",
    "performance_metrics = pd.read_json(response.performance_metrics)\n",
    "print(\"performance_metrics\")\n",
    "print(performance_metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can also save the results shown above to your disk, e.g.\n",
    "predicted_prob_test.to_csv(os.path.join(\".\", \"predicted_prob_test.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " 'eda_describe',\n",
       " 'feature_importance',\n",
       " 'lab_test',\n",
       " 'performance_metrics',\n",
       " 'predicted_prob_cv',\n",
       " 'predicted_prob_test',\n",
       " 'predicted_targets_cv',\n",
       " 'predicted_targets_test',\n",
       " 'success']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(response)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fdc63ddbea640049c0ebb823d00c0f37262ff671ac735114f7c5ea4f37555b87"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "311.806px",
    "left": "878.178px",
    "right": "20px",
    "top": "13.9653px",
    "width": "540.984px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
